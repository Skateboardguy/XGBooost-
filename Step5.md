æ­¥é©Ÿ 5) åœ¨ Validation ä¸Šèª¿åƒï¼Œä¸¦ç”¨ early_stopping æ‰¾æœ€ä½³è¿­ä»£æ•¸
(a) å®šç¾©æœå°‹ç©ºé–“
search_space = [
    (0.05, 3), (0.05, 4), (0.05, 5),
    (0.10, 3), (0.10, 4), (0.10, 5),
    (0.20, 3), (0.20, 4), (0.20, 5),
]
ğŸ‘‰ æˆ‘å€‘è¦æ¸¬è©¦ä¸åŒ learning_rate èˆ‡ max_depth çš„çµ„åˆï¼ˆå…± 9 ç¨®ï¼‰ã€‚
 
(b) è¿´åœˆå˜—è©¦æ¯ä¸€çµ„çµ„åˆ
for lr, depth in search_space:
    model = xgb.XGBClassifier(**{**base_params, "learning_rate": lr, "max_depth": depth})
ğŸ‘‰ å»ºç«‹æ¨¡å‹ï¼ŒæŠŠ åŸºç¤åƒæ•¸ + æœå°‹çµ„åˆ åˆä½µã€‚
ä¾‹å¦‚ï¼šlearning_rate=0.05, max_depth=3ã€‚
 
(c) è¨“ç·´ä¸¦ç›£æ§ Validation
    model.fit(
        X_train, y_train,
        eval_set=[(X_valid, y_valid)],
        verbose=False,
        early_stopping_rounds=50
    )
â€¢	eval_set â†’ æŒ‡å®šç›£æ§çš„é©—è­‰é›† (Validation)ã€‚
â€¢	early_stopping_rounds=50 â†’ å¦‚æœé€£çºŒ 50 æ¬¡è¿­ä»£æ²’æœ‰é€²æ­¥ï¼Œå°±è‡ªå‹•åœæ­¢ã€‚
â€¢	model.best_iteration â†’ ç´€éŒ„æœ€ä½³æ¨¹çš„æ•¸é‡ã€‚
 
(d) è¨ˆç®—é©—è­‰é›† AUC
    valid_prob = model.predict_proba(X_valid)[:, 1]
    valid_auc = roc_auc_score(y_valid, valid_prob)
ğŸ‘‰ ç”¨ AUC ç•¶æ¨¡å‹å¥½å£çš„è©•ä¼°æ¨™æº–ã€‚
 
(e) ä¿ç•™æœ€ä½³çµ„åˆ
    if valid_auc > best_valid_auc:
        best_valid_auc = valid_auc
        best_cfg = {"learning_rate": lr, "max_depth": depth}
        best_boosting_rounds = model.best_iteration + 1
ğŸ‘‰ æ›´æ–°æœ€ä½³åƒæ•¸çµ„åˆï¼Œä¸¦è¨˜éŒ„ä¸‹ã€Œæœ€ä½³è¿­ä»£æ•¸ã€ã€‚
